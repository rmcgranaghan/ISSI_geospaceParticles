{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script was created to be the only script used to prepare the ML DB for model training and evaluation and to standardize the data preparation for each of the investigations so that one process can be described and the investigations have common data preparation practices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T14:26:00.555159Z",
     "start_time": "2020-01-14T14:26:00.552008Z"
    }
   },
   "source": [
    "## Dependencies and Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:31:28.065364Z",
     "start_time": "2020-02-04T15:31:28.056245Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "from os.path import isfile, join\n",
    "from sys import getsizeof\n",
    "\n",
    "def outlier_detect_and_replace(df,str_id,outlier_value):\n",
    "    \"\"\"This function takes a dataframe, finds any columns \n",
    "    matching 'str_id' in the provided dataframe, and replaces\n",
    "    all values that exceed the 'outlier_value' with NaN\"\"\"\n",
    "#     print('working on {} outlier detection and removal'.format(str_id))\n",
    "#     print('outlier value = {}'.format(outlier_value))\n",
    "\n",
    "    cols = [ col for col in df.columns if str_id in col]\n",
    "#     print('will detect and replace for columns = {}'.format(cols))\n",
    "    for i in cols:\n",
    "        df[i][ df[i] > outlier_value ] = np.NaN\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T14:45:02.194780Z",
     "start_time": "2020-02-04T14:45:02.192140Z"
    }
   },
   "outputs": [],
   "source": [
    "DMSP_FIGURE_DIR = '/Users/ryanmcgranaghan/Documents/DMSPdata/figures/'\n",
    "DMSP_DATA_DIR = '/Users/ryanmcgranaghan/Documents/DMSPdata/data/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for ML exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:31:31.369157Z",
     "start_time": "2020-02-04T15:31:31.341780Z"
    }
   },
   "outputs": [],
   "source": [
    "def ml_db_preparation(cols_to_drop, file_save_df_cumulative):\n",
    "# def ml_db_preparation(cols_to_drop, file_save_X, file_save_y):\n",
    "    ''' \n",
    "        INPUTS: \n",
    "        - cols_to_drop: list of columns in ML_DB csv files that need to be dropped from the DB that will be output\n",
    "            --> Sample call to create: \n",
    "                      cols_to_drop = [c for c in df.columns if ('sin' in c) | ('cos' in c) | ('STD' in c) | ('AVG' in c)]\n",
    "        - file_save_df_cumulative: filename in which to save cumulative data frame\n",
    "            --> 'ML_DB_subsamp_ext_full_dfCumulative_simpleHemisphereCombine_colsDropped.csv'\n",
    "        (not used currently) - file_save_X: filename in which to save X data\n",
    "            --> 'ML_DB_subsamp_ext_full_X_simpleHemisphereCombine_colsDropped.csv'\n",
    "        (not used currently) - file_save_y: filename in which to save y data\n",
    "            --> 'ML_DB_subsamp_ext_full_y_simpleHemisphereCombine_colsDropped.csv'\n",
    "    \n",
    "        Dependencies:\n",
    "          - DMSP_DATA_DIR: Directory location that contains the ML_DB csv files\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    DMSP_DATA_DIR = '/Users/ryanmcgranaghan/Documents/DMSPdata/data/'\n",
    "\n",
    "    flag_cumulative = 'start'\n",
    "\n",
    "    for yr in np.arange(1987,2015):\n",
    "        flag = 'start'\n",
    "\n",
    "        print('year = {}'.format(yr))\n",
    "\n",
    "        # CHECK FOR EXISTENCE OF DATA FOR THIS YEAR\n",
    "        files = glob.glob(DMSP_DATA_DIR + 'ML_DB_subsamp_ext_'+str(yr)+'_sat*.csv')\n",
    "        files.sort()\n",
    "\n",
    "        if not files:\n",
    "            print('\\n\\n no files for year = {} continuing...\\n\\n'.format(yr))\n",
    "            continue\n",
    "\n",
    "        # READ IN AND CONCATENATE ALL DATA FOR CURRENT YEAR\n",
    "\n",
    "        for s in range(len(files)):\n",
    "            sat = files[s][-7:-4]\n",
    "\n",
    "            print('    satellite = {}'.format(sat))\n",
    "\n",
    "    #         if (yr == 2010) & (sat == 'f16'):\n",
    "    #             df_val = pd.read_csv(files[s])\n",
    "    #             col_idx = df_val.columns.get_loc('SC_AACGM_LAT')\n",
    "    #             df_val.loc[df_val['SC_AACGM_LAT']<=-45.,'SC_AACGM_LAT'] = df_val.loc[df_val['SC_AACGM_LAT']<=-45.,'SC_AACGM_LAT'] * -1\n",
    "    #             df_val[df_val['SC_AACGM_LAT']<=45.] = np.nan\n",
    "\n",
    "    #             # Clean up the columns and redefine the datetime as the index\n",
    "    #             df_val.index = pd.DatetimeIndex( df_val['Unnamed: 0'] )\n",
    "    #             df_val.index.names = ['Datetimes']\n",
    "    #             df_val.drop(['Unnamed: 0','key_0'], axis=1, inplace=True)\n",
    "    #             print('\\n\\n\\n\\nUsing as validation year = {} and sat = {}\\n\\n\\n\\n'.format(yr,sat))\n",
    "    #             continue\n",
    "\n",
    "            df_loop = pd.read_csv(files[s])\n",
    "            # converting southern hemisphere data to positive values\n",
    "            col_idx = df_loop.columns.get_loc('SC_AACGM_LAT')\n",
    "            \n",
    "            # Process to combine northern and southern hemisphere data\n",
    "               # (a) simple approach\n",
    "#             df_loop.loc[df_loop['SC_AACGM_LAT']<=-45.,'SC_AACGM_LAT'] = df_loop.loc[df_loop['SC_AACGM_LAT']<=-45.,'SC_AACGM_LAT'] * -1\n",
    "               # (b) robust approach...forthcoming\n",
    "            cols_By = [ col for col in df_loop.columns if 'By' in col]\n",
    "            df_loop.loc[df_loop['SC_AACGM_LAT']<0.,cols_By] = df_loop.loc[df_loop['SC_AACGM_LAT']<0.,cols_By] * -1.\n",
    "            df_loop.loc[df_loop['SC_AACGM_LAT']<=0.,'SC_AACGM_LAT'] = df_loop.loc[df_loop['SC_AACGM_LAT']<0.,'SC_AACGM_LAT'] * -1.\n",
    "\n",
    "            df_loop[df_loop['SC_AACGM_LAT']<=45.] = np.nan\n",
    "\n",
    "            # Clean up the columns and redefine the datetime as the index\n",
    "            df_loop.index = pd.DatetimeIndex( df_loop['Unnamed: 0'] )\n",
    "            df_loop.index.names = ['Datetimes']\n",
    "            df_loop.drop(['Unnamed: 0','key_0'], axis=1, inplace=True)\n",
    "\n",
    "            # Concatenate the full dataframe\n",
    "            if flag == 'start':\n",
    "                print('creating master df')\n",
    "                df = df_loop\n",
    "                flag = 'initiated'\n",
    "            else:\n",
    "                df = pd.concat([df,df_loop])\n",
    "                print('size of master df = {}'.format(df.shape))\n",
    "\n",
    "            print('        size of master df = {:.3F} MB'.format(getsizeof(df) / 10**6))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # PREPARE DATA FOR ML\n",
    "\n",
    "        # Remove outliers in the DB\n",
    "        df = df.copy(deep=True)\n",
    "\n",
    "        # IMF_outlier = 1000. #9999.99\n",
    "        IMF_outlier = 200. #9999.99\n",
    "        str_id = 'B'\n",
    "        df = outlier_detect_and_replace(df,str_id,IMF_outlier)\n",
    "\n",
    "        print('--------------------------------------------------------------')\n",
    "\n",
    "        # vsw_outlier = 10000. #99999.9\n",
    "        vsw_outlier = 2000. #99999.9\n",
    "        str_id = 'vsw'\n",
    "        df = outlier_detect_and_replace(df,str_id,vsw_outlier)\n",
    "\n",
    "        print('--------------------------------------------------------------')\n",
    "\n",
    "        # vsw_outlier = 10000. #99999.9\n",
    "        vsw_outlier = 2000. #99999.9\n",
    "        str_id = 'vx'\n",
    "        df = outlier_detect_and_replace(df,str_id,vsw_outlier)\n",
    "\n",
    "        print('--------------------------------------------------------------')\n",
    "\n",
    "        # borovsky_outlier = 1e6 #df['borovsky'].quantile(.90)\n",
    "        borovsky_outlier = 1e5 #df['borovsky'].quantile(.90)\n",
    "        str_id = 'borovsky'\n",
    "        df = outlier_detect_and_replace(df,str_id,borovsky_outlier)\n",
    "\n",
    "        print('--------------------------------------------------------------')\n",
    "\n",
    "        # newell_outlier = 1e5 #df['newell'].quantile(.90)\n",
    "        newell_outlier = 9e3 #df['newell'].quantile(.90)\n",
    "        str_id = 'newell'\n",
    "        df = outlier_detect_and_replace(df,str_id,newell_outlier)\n",
    "\n",
    "        df = df.dropna()\n",
    "\n",
    "    #     save_filename = 'box_summary_DMSP_'+str(yr)+'.png'\n",
    "    #     plot_box_summary(df,DMSP_FIGURE_DIR,save_filename) \n",
    "\n",
    "\n",
    "        # Drop unwanted features\n",
    "        target_var = 'ELE_TOTAL_ENERGY_FLUX'\n",
    "        print('manually overiding user-specified column dropping for time being...storing all columms')\n",
    "#         df = df.drop(cols_to_drop,axis=1)\n",
    "\n",
    "\n",
    "        idx = np.argwhere( df['ELE_TOTAL_ENERGY_FLUX'].to_numpy()>np.quantile(df['ELE_TOTAL_ENERGY_FLUX'].to_numpy(),.999999) )\n",
    "        df.iloc[idx,:] = np.nan\n",
    "        df = df.dropna()\n",
    "\n",
    "        if flag_cumulative == 'start':\n",
    "            df_cumulative = df.copy(deep=True)\n",
    "            print('length of current years data = {}\\nlength of cumulative training data = {}'.format(len(df),len(df_cumulative)))\n",
    "            flag_cumulative = 'add'\n",
    "        else:\n",
    "            df_cumulative = pd.concat([df_cumulative,df])\n",
    "            print('length of current years data = {}\\nlength of cumulative training data = {}'.format(len(df),len(df_cumulative)))\n",
    "\n",
    "      \n",
    "    df_cumulative.to_csv(os.path.join(DMSP_DATA_DIR,file_save_df_cumulative))\n",
    "    print('cumulative DF saved to {}'.format(os.path.join(DMSP_DATA_DIR,file_save_df_cumulative)))\n",
    "\n",
    "#     X = df_cumulative[feature_cols].copy(deep=True)\n",
    "#     y = df_cumulative['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "#     y[y == 0] = 0.0001\n",
    "#     y = np.log10(y)\n",
    "    \n",
    "#     X.to_csv(os.path.join(DMSP_DATA_DIR,file_save_X))\n",
    "#     print('X data saved to {}'.format(os.path.join(DMSP_DATA_DIR,file_save_X)))\n",
    "    \n",
    "#     y.to_csv(os.path.join(DMSP_DATA_DIR,file_save_y))\n",
    "#     print('y data saved to {}'.format(os.path.join(DMSP_DATA_DIR,file_save_y)))\n",
    "\n",
    "\n",
    "    \n",
    "#     # Separate training and testing data\n",
    "#     mask_val = [(df_cumulative.index.year == 2010) & (df_cumulative['ID_SC'].values==16)]\n",
    "#     df_val = df_cumulative[mask_val[0]].copy(deep=True)\n",
    "#     df_train = df_cumulative.copy(deep=True).drop( df_cumulative.index[mask_val[0]])\n",
    "#     print('validation data shape = {}'.format(df_val.shape))\n",
    "#     print('train data shape = {}'.format(df_train.shape))\n",
    "#     print('NOTE: we will use CV on the train data below to define model training and testing data,\\n  so have called the withheld data *validation* data here')\n",
    "\n",
    "#     # Construct X and y\n",
    "#     feature_cols = [c for c in df_cumulative.columns if not 'ELE' in c]\n",
    "\n",
    "\n",
    "#     X_val = df_val[feature_cols].copy(deep=True)\n",
    "#     y_val = df_val['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "#     X_train = df_train[feature_cols].copy(deep=True)\n",
    "#     y_train = df_train['ELE_TOTAL_ENERGY_FLUX'].copy(deep=True)\n",
    "#     scaler_X = preprocessing.RobustScaler()\n",
    "#     scaler_X = scaler_X.fit(X_train.values)\n",
    "#     X_val_scaled = scaler_X.transform(X_val.values)\n",
    "#     X_train_scaled = scaler_X.transform(X_train.values)\n",
    "\n",
    "#     numFeatures = len(X_train.columns.to_list())\n",
    "#     feature_labels = X_train.columns.to_list()\n",
    "\n",
    "    return \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:48:33.481743Z",
     "start_time": "2020-02-04T15:31:33.048622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year = 1987\n",
      "    satellite = f06\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f07\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f08\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 1884\n",
      "length of cumulative training data = 1884\n",
      "year = 1988\n",
      "    satellite = f09\n",
      "creating master df\n",
      "        size of master df = 649.313 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 61\n",
      "length of cumulative training data = 1945\n",
      "year = 1989\n",
      "\n",
      "\n",
      " no files for year = 1989 continuing...\n",
      "\n",
      "\n",
      "year = 1990\n",
      "\n",
      "\n",
      " no files for year = 1990 continuing...\n",
      "\n",
      "\n",
      "year = 1991\n",
      "\n",
      "\n",
      " no files for year = 1991 continuing...\n",
      "\n",
      "\n",
      "year = 1992\n",
      "\n",
      "\n",
      " no files for year = 1992 continuing...\n",
      "\n",
      "\n",
      "year = 1993\n",
      "\n",
      "\n",
      " no files for year = 1993 continuing...\n",
      "\n",
      "\n",
      "year = 1994\n",
      "\n",
      "\n",
      " no files for year = 1994 continuing...\n",
      "\n",
      "\n",
      "year = 1995\n",
      "\n",
      "\n",
      " no files for year = 1995 continuing...\n",
      "\n",
      "\n",
      "year = 1996\n",
      "\n",
      "\n",
      " no files for year = 1996 continuing...\n",
      "\n",
      "\n",
      "year = 1997\n",
      "\n",
      "\n",
      " no files for year = 1997 continuing...\n",
      "\n",
      "\n",
      "year = 1998\n",
      "\n",
      "\n",
      " no files for year = 1998 continuing...\n",
      "\n",
      "\n",
      "year = 1999\n",
      "\n",
      "\n",
      " no files for year = 1999 continuing...\n",
      "\n",
      "\n",
      "year = 2000\n",
      "    satellite = f12\n",
      "creating master df\n",
      "        size of master df = 649.313 MB\n",
      "    satellite = f13\n",
      "size of master df = (1054080, 153)\n",
      "        size of master df = 1298.627 MB\n",
      "    satellite = f14\n",
      "size of master df = (1581120, 153)\n",
      "        size of master df = 1947.940 MB\n",
      "    satellite = f15\n",
      "size of master df = (2108160, 153)\n",
      "        size of master df = 2597.253 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 2706\n",
      "length of cumulative training data = 4651\n",
      "year = 2001\n",
      "    satellite = f12\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f13\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f14\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "    satellite = f15\n",
      "size of master df = (2102400, 153)\n",
      "        size of master df = 2590.157 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 142181\n",
      "length of cumulative training data = 146832\n",
      "year = 2002\n",
      "    satellite = f12\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f13\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f14\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 142556\n",
      "length of cumulative training data = 289388\n",
      "year = 2003\n",
      "    satellite = f13\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f14\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f15\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 160674\n",
      "length of cumulative training data = 450062\n",
      "year = 2004\n",
      "    satellite = f13\n",
      "creating master df\n",
      "        size of master df = 649.313 MB\n",
      "    satellite = f14\n",
      "size of master df = (1054080, 153)\n",
      "        size of master df = 1298.627 MB\n",
      "    satellite = f15\n",
      "size of master df = (1581120, 153)\n",
      "        size of master df = 1947.940 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 210582\n",
      "length of cumulative training data = 660644\n",
      "year = 2005\n",
      "    satellite = f13\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f14\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f15\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 191148\n",
      "length of cumulative training data = 851792\n",
      "year = 2006\n",
      "    satellite = f13\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f15\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 167773\n",
      "length of cumulative training data = 1019565\n",
      "year = 2007\n",
      "    satellite = f13\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f15\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 72882\n",
      "length of cumulative training data = 1092447\n",
      "year = 2008\n",
      "    satellite = f15\n",
      "creating master df\n",
      "        size of master df = 649.313 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 20662\n",
      "length of cumulative training data = 1113109\n",
      "year = 2009\n",
      "    satellite = f15\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 3275\n",
      "length of cumulative training data = 1116384\n",
      "year = 2010\n",
      "    satellite = f16\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f17\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f18\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 206252\n",
      "length of cumulative training data = 1322636\n",
      "year = 2011\n",
      "    satellite = f16\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f17\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f18\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 172760\n",
      "length of cumulative training data = 1495396\n",
      "year = 2012\n",
      "    satellite = f16\n",
      "creating master df\n",
      "        size of master df = 649.313 MB\n",
      "    satellite = f17\n",
      "size of master df = (1054080, 153)\n",
      "        size of master df = 1298.627 MB\n",
      "    satellite = f18\n",
      "size of master df = (1581120, 153)\n",
      "        size of master df = 1947.940 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 156530\n",
      "length of cumulative training data = 1651926\n",
      "year = 2013\n",
      "    satellite = f16\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f17\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f18\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 147791\n",
      "length of cumulative training data = 1799717\n",
      "year = 2014\n",
      "    satellite = f16\n",
      "creating master df\n",
      "        size of master df = 647.539 MB\n",
      "    satellite = f17\n",
      "size of master df = (1051200, 153)\n",
      "        size of master df = 1295.078 MB\n",
      "    satellite = f18\n",
      "size of master df = (1576800, 153)\n",
      "        size of master df = 1942.618 MB\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "--------------------------------------------------------------\n",
      "manually overiding user-specified column dropping for time being...storing all columms\n",
      "length of current years data = 147299\n",
      "length of cumulative training data = 1947016\n",
      "cumulative DF saved to /Users/ryanmcgranaghan/Documents/DMSPdata/data/ML_DB_subsamp_ext_full_dfCumulative_complexHemisphereCombine.csv\n"
     ]
    }
   ],
   "source": [
    "# Run the function once to create one cumulative DF\n",
    "file_save_df_cumulative = 'ML_DB_subsamp_ext_full_dfCumulative_complexHemisphereCombine.csv'\n",
    "ml_db_preparation([], file_save_df_cumulative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T14:26:37.867859Z",
     "start_time": "2020-01-14T14:26:37.864930Z"
    }
   },
   "source": [
    "## Save ML DBs for various explorations - note that we moved these to the functions in which they are needed\n",
    "\n",
    "*for instance: we create the final database for hyperparameter tuning in 'Explore_ML_DB_hyperParameterExploration.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T15:48:33.504786Z",
     "start_time": "2020-02-04T15:48:33.496976Z"
    }
   },
   "outputs": [],
   "source": [
    "# For hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T14:38:26.509887Z",
     "start_time": "2020-02-04T14:38:26.507429Z"
    }
   },
   "outputs": [],
   "source": [
    "# For feature importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T14:38:24.645399Z",
     "start_time": "2020-02-04T14:38:24.642764Z"
    }
   },
   "outputs": [],
   "source": [
    "# For time history importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data volume exploration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
